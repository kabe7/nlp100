# 第9章: ベクトル空間法 (I)

## 80: コーパスの制定

`re.sub`で置換かける

## 81: 複合語からなる国名への対処

- 複合語の国名リストをつくる
- 正規表現で一行ずつ処理

複数語を一括で置換する方法([teratail](https://teratail.com/questions/9921()))

## 82. 文脈の抽出

素直に出力すると5GB位のファイルになる。

## 83 単語／文脈の頻度の計測

82の出力から単語の辞書を作る際は

```bash
cat ~/tmp/09/corpus.txt | awk -f count.awk
```

を使う。普通にやるとメモリを10GB近く食うので注意.
データのうちf(t,c) >= 10となるものだけをdata/ftc内においてある。
84のために、データはソートしておく

file | lines | size | filter
---|---|---|---
ftc.count10 | 5544271 | 86M | f(t,c)>=10
ftx.count10 | 359513 | 3.9M | f(t,*)>=5
fxc.count10 | 714786 | 8.4M | f(*,c)>=10

Nは`cat ~/tmp/09/corpus.txt | awk '{t+=(NF-1)} END {print t}'`で計算可能。
現在のデータ(in mac mini)ではN=689484568  

## 84. 単語文脈行列の作成
必要な情報だけ読み込んで、csr¥_matrixに流し込んでいく

1. まず、単語と行列indexの対応づけをする(w2num)
1. 次に、ppmiを計算するのに必要な数値を辞書で持っておく(log¥_ftx,log¥_fxc)
1. ftc.sortから疎行列を構成する要素を組み立てていく
1. csr¥_matrixコンストラクタに流し込んで完成

### 疎行列の構成について
csr_matrixはdata(非ゼロ要素), indices(非ゼロの列番号), indptr(dataのどこが行の区切り目か)の3要素からなる

ppci>0のもののみ疎行列に流し込む

## 85. 主成分分析による次元圧縮
sklearnに丸投げ

`TruncatedSVD`が疎行列PCAをやってくれる

## 86. 単語ベクトルの表示

## 87. 単語の類似度

## 88. 類似度の高い単語10件

## 89. 加法構成性によるアナロジー